{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from typing import Callable, Literal, TypeAlias\n",
    "\n",
    "import httpx\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from tabulate import tabulate\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "\n",
    "# Set device to MPS (Metal Performance Shaders) for Mac with Apple Silicon\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2389d22a4df6434990fd075404b9854c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "sae_name = \"DeepSeek-R1-Distill-Llama-8B-SAE-l19\"\n",
    "\n",
    "file_path = hf_hub_download(\n",
    "    repo_id=f\"qresearch/{sae_name}\",\n",
    "    filename=f\"{sae_name}.pt\",\n",
    "    repo_type=\"model\"\n",
    ")\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"bfloat16\", device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datasets\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gsm8k = datasets.load_dataset(\"gsm8k\", \"main\", cache_dir='/tmp')\n",
    "gsm8k_train, gsm8k_test = gsm8k['train'], gsm8k['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm8k_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 1319\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsm8k_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Testing library\n",
    "\n",
    "def find_numbers(x: str) -> list[str]:\n",
    "  \"\"\"Finds all numbers in a string.\"\"\"\n",
    "  # Search for number, possibly negative (hyphen), with thousand separators\n",
    "  # (comma), and with a decimal point (period inbetween digits).\n",
    "  numbers = re.compile(\n",
    "      r'-?[\\d,]*\\.?\\d+',\n",
    "      re.MULTILINE | re.DOTALL | re.IGNORECASE,\n",
    "  ).findall(x)\n",
    "  return numbers\n",
    "\n",
    "\n",
    "def find_number(x: str,\n",
    "                answer_delimiter: str = 'The answer is') -> str:\n",
    "  \"\"\"Finds the most relevant number in a string.\"\"\"\n",
    "  # If model uses boxed format, extract the number from \\boxed{ANSWER}\n",
    "  boxed_match = re.search(r'\\\\boxed\\{([^}]+)\\}', x)\n",
    "  if boxed_match:\n",
    "    boxed_content = boxed_match.group(1)\n",
    "    numbers = find_numbers(boxed_content)\n",
    "    if numbers:\n",
    "      return numbers[0]\n",
    "    return boxed_content  # Return the content even if it's not a number\n",
    "    \n",
    "  # If model uses the answer delimiter, then select the first number following\n",
    "  # that format.\n",
    "  if answer_delimiter in x:\n",
    "    answer = x.split(answer_delimiter)[-1]\n",
    "    numbers = find_numbers(answer)\n",
    "    if numbers:\n",
    "      return numbers[0]\n",
    "\n",
    "  # In general, select the last number in the string.\n",
    "  numbers = find_numbers(x)\n",
    "  if numbers:\n",
    "    return numbers[-1]\n",
    "  return ''\n",
    "\n",
    "\n",
    "def maybe_remove_comma(x: str) -> str:\n",
    "  # Example: 5,600 -> 5600\n",
    "  return x.replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')  # Suppress all other warnings\n",
    "os.environ['TRANSFORMERS_VERBOSITY'] = 'error'  # Suppress transformer warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_id 0\n",
      "<｜Assistant｜><think>\n",
      "Okay, so I need to figure out how much money Janet makes every day from selling her duck eggs. Let me try to break this down step by step.\n",
      "\n",
      "First, Janet's ducks lay 16 eggs per day. That's the total number of eggs she gets each day. So, 16 eggs in total.\n",
      "\n",
      "Now, she does a few things with these eggs. She eats three for breakfast every morning. So, that's 3 eggs used for breakfast. Then, she bakes muffins for her friends every day with four eggs. Wait, does that mean she uses 4 eggs per day for baking muffins? So, 4 eggs go into the muffins each day.\n",
      "\n",
      "So, let me add up the eggs she uses. She eats 3 eggs for breakfast and uses 4 eggs for baking muffins. So, 3 plus 4 is 7 eggs used each day.\n",
      "\n",
      "She starts with 16 eggs, uses 7, so how many does she have left? Let me subtract 7 from 16. 16 minus 7 is 9. So, she has 9 eggs remaining after breakfast and baking.\n",
      "\n",
      "Then, she sells the remainder at the farmers' market daily for $2 per fresh duck egg. So, she sells 9 eggs at $2 each. To find out how much money she makes, I need to multiply the number of eggs she sells by the price per egg.\n",
      "\n",
      "So, 9 eggs times $2 per egg. Let me calculate that. 9 times 2 is 18. So, she makes $18 each day from selling the eggs.\n",
      "\n",
      "Wait, let me double-check my calculations to make sure I didn't make a mistake. Starting with 16 eggs, subtracting 3 for breakfast and 4 for muffins gives 9 eggs. 9 times $2 is indeed $18. Hmm, that seems right.\n",
      "\n",
      "Is there another way to approach this problem? Maybe by calculating how many eggs she uses in total each day and then subtracting that from the total production.\n",
      "\n",
      "She uses 3 eggs for breakfast and 4 for muffins, so that's 7 eggs used. 16 minus 7 is 9, which she sells. 9 times $2 is $18. Yep, same result.\n",
      "\n",
      "I think that's solid. So, every day, Janet makes $18 from selling her eggs at the farmers' market.\n",
      "\n",
      "**Final Answer**\n",
      "\\boxed{18}\n",
      "</think>\n",
      "\n",
      "Janet’s ducks lay 16 eggs per day. She uses 3 eggs for breakfast and 4 eggs for baking muffins, which totals 7 eggs used each day. \n",
      "\n",
      "The number of eggs she has left to sell is calculated as follows:\n",
      "\\[ 16 - 3 - 4 = 9 \\]\n",
      "\n",
      "She sells these 9 eggs at $2 per egg. Therefore, the amount of money she makes each day is:\n",
      "\\[ 9 \\times 2 = 18 \\]\n",
      "\n",
      "\\[\n",
      "\\boxed{18}\n",
      "\\]\n",
      "Short answer: 18\n",
      "----------------------------------------\n",
      "Ground truth answer Janet sells 16 - 3 - 4 = <<16-3-4=9>>9 duck eggs a day.\n",
      "She makes 9 * 2 = $<<9*2=18>>18 every day at the farmer’s market.\n",
      "#### 18\n",
      "Short ground truth answer 18\n",
      "Correct: 1 out of 1\n",
      "========================================\n",
      "task_id 1\n",
      "<｜Assistant｜><think>\n",
      "Okay, so I have this problem here about making a robe, and I need to figure out how many bolts of fabric it takes. Let me read it again: \"A robe takes 2 bolts of blue fiber and half that much white fiber. How many bolts in total does it take?\" Hmm, okay. So, it's talking about two different types of fiber—blue and white—and how many bolts each type is needed. \n",
      "\n",
      "Alright, let me break this down. First, it says the robe takes 2 bolts of blue fiber. That part is straightforward. So, blue fiber requires 2 bolts. Now, the next part is a bit trickier: \"half that much white fiber.\" Hmm, so white fiber is half as much as blue fiber. \n",
      "\n",
      "Wait, so if blue fiber is 2 bolts, then half of that would be... let me calculate. Half of 2 is 1, right? So, white fiber would require 1 bolt. So, blue is 2, white is 1. Now, the question is asking for the total number of bolts. So, I just need to add those two together. \n",
      "\n",
      "Let me write that out to make sure I don't make a mistake. Blue fiber: 2 bolts. White fiber: half of 2 is 1 bolt. Total bolts = 2 + 1. That equals 3. So, the total number of bolts needed is 3. \n",
      "\n",
      "Wait, let me double-check. Sometimes when problems mention \"half that much,\" it can be a bit confusing. So, if blue is 2, then white is half of 2, which is indeed 1. So, adding them together, 2 + 1, gives 3. Yeah, that seems right. \n",
      "\n",
      "Is there another way to think about this? Maybe using multiplication or something? Let me see. If blue is 2, then white is half of that, so 2 multiplied by 0.5 is 1. So, 2 + 1 is still 3. Yep, same result. \n",
      "\n",
      "Alternatively, I can think of it as fractions. Blue is 2, which is 2/1. White is half of that, so that's (2/1) * (1/2) = 1. So, again, 2 + 1 is 3. \n",
      "\n",
      "Hmm, seems consistent across different methods. Maybe I can visualize it. Imagine I have 2 blue bolts. Each white bolt is half the size or half the amount needed. So, if each blue bolt is, say, 1 unit, then each white bolt is 0.5 units. So, 2 blue bolts would be 2 units, and 1 white bolt would be 0.5 units. Total fabric needed is 2 + 0.5 = 2.5 units. But wait, the question is about bolts, not units of fabric. So, each bolt is a unit, right? So, 2 blue bolts and 1 white bolt make 3 bolts in total. \n",
      "\n",
      "Wait, hold on. Is the question asking for the total number of bolts or the total amount of fabric? It says, \"How many bolts in total does it take?\" So, it's about the number of bolts, not the amount of fabric. So, each bolt is a unit, so 2 blue bolts and 1 white bolt is 3 bolts. \n",
      "\n",
      "I think I was overcomplicating it for a second there, thinking about units of fabric, but the question is specifically about bolts. So, each bolt is a separate unit, regardless of the type of fiber. So, 2 blue bolts and 1 white bolt is 3 bolts. \n",
      "\n",
      "Let me make sure I didn't misinterpret the question. It says, \"A robe takes 2 bolts of blue fiber and half that much white fiber.\" So, 2 blue, and half of 2 is 1 white. So, 2 + 1 is 3. Yeah, that seems correct. \n",
      "\n",
      "Is there a chance that \"half that much\" refers to half the total? Like, half of the total bolts? But that wouldn't make much sense because it says \"half that much white fiber,\" referring to the blue fiber. So, it's half of the blue fiber's amount. So, 2 blue, 1 white. \n",
      "\n",
      "Alternatively, if it had said, \"half as much in total,\" that might be different, but it's not. It's specifically talking about white fiber being half that much as blue fiber. So, 2 blue, 1 white. \n",
      "\n",
      "I think I'm confident now. The total number of bolts is 3. So, the answer is 3.\n",
      "\n",
      "**Final Answer**\n",
      "The total number of bolts needed is \\boxed{3}.\n",
      "</think>\n",
      "\n",
      "The problem states that a robe takes 2 bolts of blue fiber and half that much white fiber. \n",
      "\n",
      "1. The amount of blue\n",
      "Short answer: 3\n",
      "----------------------------------------\n",
      "Ground truth answer It takes 2/2=<<2/2=1>>1 bolt of white fiber\n",
      "So the total amount of fabric is 2+1=<<2+1=3>>3 bolts of fabric\n",
      "#### 3\n",
      "Short ground truth answer 3\n",
      "Correct: 2 out of 2\n",
      "========================================\n",
      "task_id 2\n",
      "<｜Assistant｜><think>\n",
      "Okay, so Josh is trying to flip a house, which sounds like a cool idea, but I need to figure out how much profit he made. Let me break down the problem step by step.\n",
      "\n",
      "First, Josh buys a house for $80,000. That's his initial investment. Then, he decides to put in some repairs, which cost him $50,000. So, he's spending a total of $80,000 + $50,000, which is $130,000. But wait, the problem says that these repairs increased the value of the house by 150%. Hmm, I need to make sure I understand what that means.\n",
      "\n",
      "When it says the repairs increased the value by 150%, does that mean the total value after repairs is 150% of the original value, or does it mean the value increased by 150% of the original? I think it's the latter because it says \"increased by 150%.\" So, if the original value was $80,000, increasing that by 150% would mean adding 150% of $80,000 to the original price.\n",
      "\n",
      "Let me calculate that. 150% of $80,000 is 0.15 * 80,000, which is $12,000. So, the total value after repairs would be the original price plus the increase, which is $80,000 + $12,000 = $92,000. Wait, but hold on, Josh actually spent $50,000 on repairs. So, is the $50,000 the total cost of repairs, or is it 150% of the original value?\n",
      "\n",
      "I think I need to clarify this. The problem says he put in $50,000 in repairs, which increased the value by 150%. So, the $50,000 is the amount he spent on repairs, and that resulted in a 150% increase in the house's value. So, the original value was $80,000, and after repairs, the value is 150% higher.\n",
      "\n",
      "So, 150% of $80,000 is $12,000, as I calculated before. So, the total value after repairs is $80,000 + $12,000 = $92,000. But Josh spent $50,000 on repairs. So, is the $92,000 the selling price, and he made a profit of $92,000 - his total costs?\n",
      "\n",
      "Wait, his total costs are the purchase price plus the repair costs, which is $80,000 + $50,000 = $130,000. So, if he sold the house for $92,000, his profit would be $92,000 - $130,000, which is a negative number. That can't be right because flipping houses is supposed to make a profit, not a loss.\n",
      "\n",
      "Hmm, maybe I misunderstood the problem. Let me read it again: \"He buys a house for $80,000 and then puts in $50,000 in repairs. This increased the value of the house by 150%. How much profit did he make?\"\n",
      "\n",
      "So, perhaps the $50,000 is the amount that increased the value by 150%. So, the $50,000 is 150% of the original value. Let me check that. If $50,000 is 150% of $80,000, then 150% of $80,000 is indeed $50,000 because 0.15 * 80,000 = 50,000. So, that makes sense.\n",
      "\n",
      "So, the $50,000 he spent on repairs is equal to 150% of the original value. Therefore, the total value after repairs is the original value plus 150% of it, which is 100% + 150% = 250% of the original value. So, 250% of $80,000 is 2.5 * 80,000 = $200,000.\n",
      "\n",
      "So, the house is now worth $200,000 after the repairs. Josh's total investment was $80,000 + $50,000 = $130,000. Therefore, his profit is the selling price minus his total costs, which is $200,000 - $130,000 = $70,000.\n",
      "\n",
      "Wait, that seems more reasonable. So, he made a $70,000 profit. Let me just verify that again.\n",
      "\n",
      "Original price: $80,000.\n",
      "\n",
      "He spends $50,000 on repairs, which is 150% of the original price. So, the value after repairs is 100% + 150% = 250% of the original, which is 2.5 * 80,000 = $200,000.\n",
      "\n",
      "Total cost to Josh: $80,000 (purchase) + $50,000 (repairs) = $130,000.\n",
      "\n",
      "Profit: $200,000 (selling price) - $130,000 (total cost) = $70,000.\n",
      "\n",
      "Yes, that seems correct. So,\n",
      "Short answer: 70000\n",
      "----------------------------------------\n",
      "Ground truth answer The cost of the house and repairs came out to 80,000+50,000=$<<80000+50000=130000>>130,000\n",
      "He increased the value of the house by 80,000*1.5=<<80000*1.5=120000>>120,000\n",
      "So the new value of the house is 120,000+80,000=$<<120000+80000=200000>>200,000\n",
      "So he made a profit of 200,000-130,000=$<<200000-130000=70000>>70,000\n",
      "#### 70000\n",
      "Short ground truth answer 70000\n",
      "Correct: 3 out of 3\n",
      "========================================\n",
      "task_id 3\n",
      "<｜Assistant｜><think>\n",
      "First, determine the number of sprints James runs each week by multiplying the number of sprints per session by the number of sessions per week.\n",
      "\n",
      "Next, calculate the total distance for each session by multiplying the number of sprints by the distance of each sprint.\n",
      "\n",
      "Finally, find the total weekly distance by multiplying the total distance per session by the number of sessions per week.\n",
      "</think>\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "Let's break down the problem step by step.\n",
      "\n",
      "1. **Determine the number of sprints per week:**\n",
      "   \n",
      "   - **Sprints per session:** 3\n",
      "   - **Sessions per week:** 3\n",
      "   \n",
      "   \\[\n",
      "   \\text{Total sprints per week} = 3 \\text{ sprints/session} \\times 3 \\text{ sessions/week} = 9 \\text{ sprints}\n",
      "   \\]\n",
      "\n",
      "2. **Calculate the total distance for each session:**\n",
      "   \n",
      "   - **Distance per sprint:** 60 meters\n",
      "   \n",
      "   \\[\n",
      "   \\text{Total distance per session} = 3 \\text{ sprints} \\times 60 \\text{ meters/sprint} = 180 \\text{ meters}\n",
      "   \\]\n",
      "\n",
      "3. **Find the total weekly distance:**\n",
      "   \n",
      "   \\[\n",
      "   \\text{Total weekly distance} = 3 \\text{ sessions/week} \\times 180 \\text{ meters/session} = 540 \\text{ meters}\n",
      "   \\]\n",
      "\n",
      "**Final Answer:**\n",
      "\n",
      "\\[\n",
      "\\boxed{540}\n",
      "\\]\n",
      "Short answer: 540\n",
      "----------------------------------------\n",
      "Ground truth answer He sprints 3*3=<<3*3=9>>9 times\n",
      "So he runs 9*60=<<9*60=540>>540 meters\n",
      "#### 540\n",
      "Short ground truth answer 540\n",
      "Correct: 4 out of 4\n",
      "========================================\n",
      "task_id 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:37\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/arena-env/lib/python3.11/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/arena-env/lib/python3.11/site-packages/transformers/generation/utils.py:2047\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2040\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2041\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   2042\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2043\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2044\u001b[0m     )\n\u001b[1;32m   2046\u001b[0m     \u001b[38;5;66;03m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 2047\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2048\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2049\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2050\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2051\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2052\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2054\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2055\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   2058\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2059\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2060\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2061\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2066\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2067\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/arena-env/lib/python3.11/site-packages/transformers/generation/utils.py:3052\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3049\u001b[0m     next_tokens \u001b[38;5;241m=\u001b[39m next_tokens \u001b[38;5;241m*\u001b[39m unfinished_sequences \u001b[38;5;241m+\u001b[39m pad_token_id \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m unfinished_sequences)\n\u001b[1;32m   3051\u001b[0m \u001b[38;5;66;03m# update generated ids, model inputs, and length for next step\u001b[39;00m\n\u001b[0;32m-> 3052\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_tokens\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streamer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3054\u001b[0m     streamer\u001b[38;5;241m.\u001b[39mput(next_tokens\u001b[38;5;241m.\u001b[39mcpu())\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_correct = 0\n",
    "all_responses = {}\n",
    "short_responses = {}\n",
    "idx = 0\n",
    "correct = 0\n",
    "\n",
    "# Create output directories if they don't exist\n",
    "os.makedirs('outputs/gsm8k', exist_ok=True)\n",
    "os.makedirs('outputs/gsm8k/raw_outputs', exist_ok=True)\n",
    "os.makedirs('outputs/gsm8k/decoded_text', exist_ok=True)\n",
    "\n",
    "TEMPLATE = \"\"\"\n",
    "Q: {question}\n",
    "A:\"\"\"\n",
    "\n",
    "for task_id, problem in enumerate(gsm8k_test):\n",
    "\n",
    "    if task_id in all_responses: continue\n",
    "\n",
    "    # Print Task ID\n",
    "    print(f\"task_id {task_id}\")\n",
    "\n",
    "    # Formulate the prompt for DeepSeek Distill model\n",
    "    prompt = TEMPLATE.format(question=problem['question'])\n",
    "    \n",
    "    # Generate response using the model with chat template\n",
    "    inputs = tokenizer.apply_chat_template(\n",
    "        [\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        add_generation_prompt=True,\n",
    "        return_tensors=\"pt\",\n",
    "        return_dict=True,\n",
    "    ).to(device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs[\"input_ids\"],\n",
    "            attention_mask=inputs[\"attention_mask\"],\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            max_new_tokens=1024,\n",
    "            do_sample=False,\n",
    "            temperature=None,\n",
    "            top_p=None\n",
    "        )\n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Extract the assistant's response (after the prompt)\n",
    "    response_parts = full_response.split(prompt)\n",
    "    if len(response_parts) > 1:\n",
    "        response_text = response_parts[1].strip()\n",
    "    else:\n",
    "        response_text = full_response\n",
    "    \n",
    "    print(response_text)\n",
    "    \n",
    "    # Save raw outputs\n",
    "    torch.save(outputs, f'outputs/gsm8k/raw_outputs/output_{task_id}.pt')\n",
    "    \n",
    "    # Save decoded text\n",
    "    with open(f'outputs/gsm8k/decoded_text/text_{task_id}.txt', 'w') as f:\n",
    "        f.write(response_text)\n",
    "    \n",
    "    all_responses[task_id] = response_text\n",
    "    short_responses[task_id] = maybe_remove_comma(find_number(all_responses[task_id]))\n",
    "    print(f\"Short answer: {short_responses[task_id]}\")\n",
    "    try:\n",
    "        correct += float(maybe_remove_comma(\n",
    "            find_number(problem['answer']))) == float(short_responses[task_id])\n",
    "    except:\n",
    "        correct += maybe_remove_comma(\n",
    "            find_number(problem['answer'])) == maybe_remove_comma(\n",
    "                find_number(short_responses[task_id]))\n",
    "    print('-'*40)\n",
    "    print(f\"Ground truth answer {problem['answer']}\")\n",
    "    print(f\"Short ground truth answer {find_number(problem['answer'])}\")\n",
    "    print(f\"Correct: {correct} out of {idx+1}\")\n",
    "    print(\"=\"*40)\n",
    "    idx += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arena-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
