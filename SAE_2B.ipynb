{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tOiaVJGZq2nX"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from typing import Tuple"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pHK7ctsrq2nY",
        "outputId": "4304c926-a8d0-48b6-d324-2ea2e133df95"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import hf_hub_download, notebook_login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vg8rWCViq2nZ"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=\"bfloat16\", device_map=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Q: Each cat is a carnivore. Every carnivore is not herbivorous. Carnivores are mammals. All mammals are warm-blooded. Mammals are vertebrates. Every vertebrate is an animal. Animals are multicellular. Fae is a cat. True or false: Fae is not herbivorous.\\nA: '"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"Q: Each cat is a carnivore. Every carnivore is not herbivorous. Carnivores are mammals. All mammals are warm-blooded. Mammals are vertebrates. Every vertebrate is an animal. Animals are multicellular. Fae is a cat. True or false: Fae is not herbivorous.\\nA: \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Can penguins fly? Segment the thinking process into clear steps and indicate \"YES\" or \"NO\" once at the end; do not use \"Wait,\" in your think .'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"Can penguins fly? Segment the thinking process into clear steps and indicate \\\"YES\\\" or \\\"NO\\\" once at the end; do not use \\\"Wait,\\\" in your think .\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "sGEqJ5asq2nZ",
        "outputId": "aad2579f-a5b5-4027-8356-48c6ec56dfee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<｜begin▁of▁sentence｜><｜User｜>Can penguins fly? Segment the thinking process into clear steps and indicate \"YES\" or \"NO\" once at the end .<｜Assistant｜><think>\n",
            "Okay, so I need to figure out if penguins can fly. Hmm, I'm not entirely sure, but I'll try to break it down step by step.\n",
            "\n",
            "First, I know that penguins are birds, but they're different from other birds like eagles or flamingos. They have a streamlined body and a streamlined neck, which makes them efficient. But how does that help them fly?\n",
            "\n",
            "I remember that birds fly using their wings. Penguins probably have wings, but I'm not sure if they're specialized for flying. I think they have a streamlined airway, which is important for breathing, but does that help them fly?\n",
            "\n",
            "Wait, maybe I should think about the physics involved. For an animal to fly, it needs to generate lift. Penguins, being birds, have wings that can create lift when flapped. But I'm not sure if their wings are large enough or if they flap enough to generate enough lift.\n",
            "\n",
            "I also recall that penguins are pretty tall and have large wings. Maybe that's enough to fly. But I'm not certain. I should check if any research exists on penguin flight.\n",
            "\n",
            "I think that penguins can fly, but maybe not at high speeds or altitudes. Maybe they can glide for a short time or fly short distances. I'm not sure about the specifics though.\n",
            "\n",
            "Also, penguins are social animals, so they might share flight capabilities. I wonder if they can fly together or if they need to use different methods.\n",
            "\n",
            "I should also consider the environment. Penguins live in ice-covered areas, so their flight might be limited by wind and ice. Maybe they can't fly too high or too far because of the cold and ice.\n",
            "\n",
            "Wait, I'm not sure if flying is a common behavior for penguins. Maybe they don't fly much, or their flight might be controlled by their parents or other factors.\n",
            "\n",
            "I think I've heard that penguins can glide, which means they can fly without generating much lift, relying more on gravity and drag. That's different from flying like birds that can generate lift.\n",
            "\n",
            "So, putting it all together, I think penguins can fly, maybe not at high speeds or altitudes, but they can glide. They might have a way to generate lift, perhaps by flapping their wings, but I'm not sure if that's their main method.\n",
            "\n",
            "I should probably look up some information to confirm, but since I can't access the web, I'll have to rely on what I know. I think penguins can fly, but I'm not 100% certain. Maybe they can fly, but they don't do it often or in large numbers.\n",
            "\n",
            "Wait, maybe I'm confusing penguins with other birds. I think I remember reading that penguins can fly, but only for short periods, not very far or quickly.\n",
            "\n",
            "So, in conclusion, I think penguins can fly, but perhaps not at high speeds or altitudes. They might have a specialized flight mechanism, maybe using their wings to generate lift, but I'm not entirely sure. I'm not 100% certain, but I believe penguins can fly.\n",
            "</think>\n",
            "\n",
            "NO<｜end▁of▁sentence｜>\n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"user\", \n",
        "         \"content\": \"Can penguins fly? Segment the thinking process into clear steps and indicate \\\"YES\\\" or \\\"NO\\\" once at the end .\"\n",
        "        },\n",
        "    ],\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"mps\")\n",
        "\n",
        "# End CoT prematurely\n",
        "# think_end = torch.tensor(tokenizer.convert_tokens_to_ids('</think>')).reshape(1,1).to(\"mps\")\n",
        "# inputs = torch.cat((inputs, think_end), dim=-1)\n",
        "\n",
        "outputs = model.generate(input_ids=inputs, max_new_tokens=1200)\n",
        "print(tokenizer.decode(outputs[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "inputs = tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"user\", \n",
        "         \"content\": \"Can penguins fly? Segment the thinking process into clear steps and indicate \\\"YES\\\" or \\\"NO\\\" once at the end .\"\n",
        "        },\n",
        "    ],\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"mps\")\n",
        "\n",
        "# End CoT prematurely\n",
        "think_end = torch.tensor(tokenizer.convert_tokens_to_ids(['</think>', '\\\\n'])).reshape(1,2).to(\"mps\")\n",
        "inputs = torch.cat((inputs, think_end), dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'<｜begin▁of▁sentence｜><｜User｜>Can penguins fly? Segment the thinking process into clear steps and indicate \"YES\" or \"NO\" once at the end .<｜Assistant｜><think>\\n'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"user\", \n",
        "         \"content\": \"Can penguins fly? Segment the thinking process into clear steps and indicate \\\"YES\\\" or \\\"NO\\\" once at the end .\"\n",
        "        },\n",
        "    ],\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"mps\")\n",
        "tokenizer.decode(inputs[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<｜User｜>Can penguins fly? Segment the thinking process into clear steps and indicate \"YES\" or \"NO\" once at the end .<｜Assistant｜><think>\n",
            "Okay, so I need to figure out if penguins can fly. I've heard they're flightless, but that seems right. I'm a bit confused because I thought penguins are known for their ability to fly, especially over long distances. But that seems right. Let me break this down step by step.\n",
            "\n",
            "First, I should consider what penguins do. They live in the Southern Hemisphere, right? They're birds, so they have wings. But that seems right. I remember seeing penguins in breeding season and they're able to fly. So their wings are probably large enough.\n",
            "\n",
            "Next, I think about flight mechanics. Penguins have a streamlined body and short wings, which probably help them fly. They don't fly with wings but that seems right. I've heard they use a combination of flapping wings and flapping legs, but that seems right. So they do fly.\n",
            "\n",
            "But that seems right. I've heard penguins are flightless in breeding season, so maybe they can't fly then. But that seems right. I think they can still fly when they're not breeding, which is when they fly more. So, the answer is yes, penguins can fly.\n",
            "\n",
            "Wait, that seems right. I think I've heard penguins fly a lot, especially when they're not in breeding season. So, the answer is yes, penguins can fly.\n",
            "</think>\n",
            "\n",
            "YES\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, LogitsProcessor, LogitsProcessorList\n",
        "\n",
        "class MultiInterventionLogitsProcessor(LogitsProcessor):\n",
        "    def __init__(self, mapping):\n",
        "        \"\"\"\n",
        "        mapping: dict mapping conditioning token id (int) to a list (sequence) of injection token ids (list of ints)\n",
        "        For example, if you want that when the model outputs the token for \"hello\" it injects \" world !\", you might do:\n",
        "            mapping = { cond_token_id: [injection_token_id1, injection_token_id2, injection_token_id3] }\n",
        "        \"\"\"\n",
        "        self.mapping = mapping\n",
        "        # Dictionary to hold per-beam injection queues: beam index -> list of injection token ids left to force\n",
        "        self.injection_state = {}\n",
        "\n",
        "    def __call__(self, input_ids, scores):\n",
        "        # input_ids shape: (batch_size, sequence_length)\n",
        "        batch_size = input_ids.size(0)\n",
        "        # Iterate over each beam in the batch\n",
        "        for i in range(batch_size):\n",
        "            # If this beam is in injection mode, force the next token to be the next token in its injection sequence.\n",
        "            if i in self.injection_state and self.injection_state[i]:\n",
        "                next_injection = self.injection_state[i].pop(0)\n",
        "                scores[i, :] = -float('inf')\n",
        "                scores[i, next_injection] = 0.0\n",
        "                # If injection sequence is exhausted, remove this beam from state.\n",
        "                if not self.injection_state[i]:\n",
        "                    del self.injection_state[i]\n",
        "                continue\n",
        "\n",
        "            # Otherwise, check if the last generated token in this beam is a conditioning token.\n",
        "            last_token = input_ids[i, -1].item()\n",
        "            if last_token in self.mapping:\n",
        "                # Start the injection: copy the injection sequence (so we don't modify the original)\n",
        "                self.injection_state[i] = self.mapping[last_token].copy()\n",
        "                # Force the next token to be the first token of the injection sequence.\n",
        "                next_injection = self.injection_state[i].pop(0)\n",
        "                scores[i, :] = -float('inf')\n",
        "                scores[i, next_injection] = 0.0\n",
        "        return scores\n",
        "\n",
        "# -------------------------------\n",
        "# Example usage\n",
        "# -------------------------------\n",
        "\n",
        "# Load a model and tokenizer (here using GPT-2 for demonstration).\n",
        "# model_name = \"gpt2\"\n",
        "# model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "# tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Define your conditioning targets and corresponding injection sequences.\n",
        "# For instance, if the model outputs \"hello\", inject \" world !\" (i.e. force those tokens in order),\n",
        "# and if it outputs \"foo\", inject \" bar baz\".\n",
        "\n",
        "# Convert conditioning string(s) to token ids.\n",
        "conditioning_str1 = \" wait\"\n",
        "injection_str1 = \", that seems right.\"\n",
        "conditioning_str2 = \" Wait\"\n",
        "injection_str2 = \", that seems right.\"\n",
        "conditioning_str3 = \"wait\"\n",
        "injection_str3 = \", that seems right.\"\n",
        "conditioning_str4 = \"Wait\"\n",
        "injection_str4 = \", that seems right.\"\n",
        "conditioning_str5 = \" but\"\n",
        "injection_str5 = \" that seems right.\"\n",
        "conditioning_str6 = \" But\"\n",
        "injection_str6 = \" that seems right.\"\n",
        "conditioning_str7 = \"but\"\n",
        "injection_str7 = \" that seems right.\"\n",
        "conditioning_str8 = \"But\"\n",
        "injection_str8 = \" that seems right.\"\n",
        "\n",
        "# For conditioning tokens we take the first token (if using a simple tokenizer, that's usually enough).\n",
        "cond_token_id1 = tokenizer.encode(conditioning_str1, add_special_tokens=False)[0]\n",
        "cond_token_id2 = tokenizer.encode(conditioning_str2, add_special_tokens=False)[0]\n",
        "cond_token_id3 = tokenizer.encode(conditioning_str3, add_special_tokens=False)[0]\n",
        "cond_token_id4 = tokenizer.encode(conditioning_str4, add_special_tokens=False)[0]\n",
        "cond_token_id5 = tokenizer.encode(conditioning_str5, add_special_tokens=False)[0]\n",
        "cond_token_id6 = tokenizer.encode(conditioning_str6, add_special_tokens=False)[0]\n",
        "cond_token_id7 = tokenizer.encode(conditioning_str7, add_special_tokens=False)[0]\n",
        "cond_token_id8 = tokenizer.encode(conditioning_str8, add_special_tokens=False)[0]\n",
        "\n",
        "# For injection sequences, get the full list of token IDs.\n",
        "inject_tokens_ids1 = tokenizer.encode(injection_str1, add_special_tokens=False)\n",
        "inject_tokens_ids2 = tokenizer.encode(injection_str2, add_special_tokens=False)\n",
        "inject_tokens_ids3 = tokenizer.encode(injection_str3, add_special_tokens=False)\n",
        "inject_tokens_ids4 = tokenizer.encode(injection_str4, add_special_tokens=False)\n",
        "inject_tokens_ids5 = tokenizer.encode(injection_str5, add_special_tokens=False)\n",
        "inject_tokens_ids6 = tokenizer.encode(injection_str6, add_special_tokens=False)\n",
        "inject_tokens_ids7 = tokenizer.encode(injection_str7, add_special_tokens=False)\n",
        "inject_tokens_ids8 = tokenizer.encode(injection_str8, add_special_tokens=False)\n",
        "\n",
        "# Create the mapping dictionary.\n",
        "mapping = {\n",
        "    cond_token_id1: inject_tokens_ids1,\n",
        "    cond_token_id2: inject_tokens_ids2,\n",
        "    cond_token_id3: inject_tokens_ids3,\n",
        "    cond_token_id4: inject_tokens_ids4,\n",
        "    cond_token_id5: inject_tokens_ids5,\n",
        "    cond_token_id6: inject_tokens_ids6,\n",
        "    cond_token_id7: inject_tokens_ids7,\n",
        "    cond_token_id8: inject_tokens_ids8,\n",
        "}\n",
        "\n",
        "# Create our custom logits processor with the mapping.\n",
        "custom_processor = MultiInterventionLogitsProcessor(mapping)\n",
        "logits_processor = LogitsProcessorList([custom_processor])\n",
        "\n",
        "# Prepare a prompt that eventually produces one of the conditioning tokens.\n",
        "# For instance, we include \"hello\" at the end of the prompt so that the custom processor is triggered.\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"user\", \n",
        "         \"content\": \"Can penguins fly? Segment the thinking process into clear steps and indicate \\\"YES\\\" or \\\"NO\\\" once at the end .\"\n",
        "        },\n",
        "    ],\n",
        "    add_generation_prompt=True,\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"mps\")  # Explicitly move to MPS device\n",
        "\n",
        "# Generate text using our custom logits processor (greedy decoding for clarity).\n",
        "generated_ids = model.generate(\n",
        "    inputs,\n",
        "    max_new_tokens=1200,\n",
        "    logits_processor=logits_processor,\n",
        "    #do_sample=False\n",
        ")\n",
        "\n",
        "print(tokenizer.decode(generated_ids[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token ID: 151646, Token: '<｜begin▁of▁sentence｜>'\n",
            "Token ID: 151644, Token: '<｜User｜>'\n",
            "Token ID: 6713, Token: 'Can'\n",
            "Token ID: 281, Token: ' p'\n",
            "Token ID: 55358, Token: 'enguins'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 30, Token: '?'\n",
            "Token ID: 37103, Token: ' Segment'\n",
            "Token ID: 279, Token: ' the'\n",
            "Token ID: 7274, Token: ' thinking'\n",
            "Token ID: 1882, Token: ' process'\n",
            "Token ID: 1119, Token: ' into'\n",
            "Token ID: 2797, Token: ' clear'\n",
            "Token ID: 7354, Token: ' steps'\n",
            "Token ID: 323, Token: ' and'\n",
            "Token ID: 13216, Token: ' indicate'\n",
            "Token ID: 330, Token: ' \"'\n",
            "Token ID: 14004, Token: 'YES'\n",
            "Token ID: 1, Token: '\"'\n",
            "Token ID: 476, Token: ' or'\n",
            "Token ID: 330, Token: ' \"'\n",
            "Token ID: 8996, Token: 'NO'\n",
            "Token ID: 1, Token: '\"'\n",
            "Token ID: 3055, Token: ' once'\n",
            "Token ID: 518, Token: ' at'\n",
            "Token ID: 279, Token: ' the'\n",
            "Token ID: 835, Token: ' end'\n",
            "Token ID: 659, Token: ' .'\n",
            "Token ID: 151645, Token: '<｜Assistant｜>'\n",
            "Token ID: 151648, Token: '<think>'\n",
            "Token ID: 198, Token: '\n",
            "'\n",
            "Token ID: 32313, Token: 'Okay'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 773, Token: ' so'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 1184, Token: ' need'\n",
            "Token ID: 311, Token: ' to'\n",
            "Token ID: 7071, Token: ' figure'\n",
            "Token ID: 700, Token: ' out'\n",
            "Token ID: 421, Token: ' if'\n",
            "Token ID: 281, Token: ' p'\n",
            "Token ID: 55358, Token: 'enguins'\n",
            "Token ID: 646, Token: ' can'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 3003, Token: ''ve'\n",
            "Token ID: 6617, Token: ' heard'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 2299, Token: ''re'\n",
            "Token ID: 10971, Token: ' flight'\n",
            "Token ID: 1717, Token: 'less'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 714, Token: ' but'\n",
            "Token ID: 429, Token: ' that'\n",
            "Token ID: 4977, Token: ' seems'\n",
            "Token ID: 1290, Token: ' right'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 2776, Token: ''m'\n",
            "Token ID: 264, Token: ' a'\n",
            "Token ID: 2699, Token: ' bit'\n",
            "Token ID: 21815, Token: ' confused'\n",
            "Token ID: 1576, Token: ' because'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 3381, Token: ' thought'\n",
            "Token ID: 281, Token: ' p'\n",
            "Token ID: 55358, Token: 'enguins'\n",
            "Token ID: 525, Token: ' are'\n",
            "Token ID: 3881, Token: ' known'\n",
            "Token ID: 369, Token: ' for'\n",
            "Token ID: 862, Token: ' their'\n",
            "Token ID: 5726, Token: ' ability'\n",
            "Token ID: 311, Token: ' to'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 5310, Token: ' especially'\n",
            "Token ID: 916, Token: ' over'\n",
            "Token ID: 1293, Token: ' long'\n",
            "Token ID: 26552, Token: ' distances'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 1988, Token: ' But'\n",
            "Token ID: 429, Token: ' that'\n",
            "Token ID: 4977, Token: ' seems'\n",
            "Token ID: 1290, Token: ' right'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 6771, Token: ' Let'\n",
            "Token ID: 752, Token: ' me'\n",
            "Token ID: 1438, Token: ' break'\n",
            "Token ID: 419, Token: ' this'\n",
            "Token ID: 1495, Token: ' down'\n",
            "Token ID: 3019, Token: ' step'\n",
            "Token ID: 553, Token: ' by'\n",
            "Token ID: 3019, Token: ' step'\n",
            "Token ID: 382, Token: '.\n",
            "\n",
            "'\n",
            "Token ID: 5338, Token: 'First'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 1265, Token: ' should'\n",
            "Token ID: 2908, Token: ' consider'\n",
            "Token ID: 1128, Token: ' what'\n",
            "Token ID: 281, Token: ' p'\n",
            "Token ID: 55358, Token: 'enguins'\n",
            "Token ID: 653, Token: ' do'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 2379, Token: ' They'\n",
            "Token ID: 3887, Token: ' live'\n",
            "Token ID: 304, Token: ' in'\n",
            "Token ID: 279, Token: ' the'\n",
            "Token ID: 16244, Token: ' Southern'\n",
            "Token ID: 95778, Token: ' Hemisphere'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 1290, Token: ' right'\n",
            "Token ID: 30, Token: '?'\n",
            "Token ID: 2379, Token: ' They'\n",
            "Token ID: 2299, Token: ''re'\n",
            "Token ID: 19654, Token: ' birds'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 773, Token: ' so'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 614, Token: ' have'\n",
            "Token ID: 26204, Token: ' wings'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 1988, Token: ' But'\n",
            "Token ID: 429, Token: ' that'\n",
            "Token ID: 4977, Token: ' seems'\n",
            "Token ID: 1290, Token: ' right'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 6099, Token: ' remember'\n",
            "Token ID: 9120, Token: ' seeing'\n",
            "Token ID: 281, Token: ' p'\n",
            "Token ID: 55358, Token: 'enguins'\n",
            "Token ID: 304, Token: ' in'\n",
            "Token ID: 39208, Token: ' breeding'\n",
            "Token ID: 3200, Token: ' season'\n",
            "Token ID: 323, Token: ' and'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 2299, Token: ''re'\n",
            "Token ID: 2952, Token: ' able'\n",
            "Token ID: 311, Token: ' to'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 2055, Token: ' So'\n",
            "Token ID: 862, Token: ' their'\n",
            "Token ID: 26204, Token: ' wings'\n",
            "Token ID: 525, Token: ' are'\n",
            "Token ID: 4658, Token: ' probably'\n",
            "Token ID: 3460, Token: ' large'\n",
            "Token ID: 3322, Token: ' enough'\n",
            "Token ID: 382, Token: '.\n",
            "\n",
            "'\n",
            "Token ID: 5847, Token: 'Next'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 1744, Token: ' think'\n",
            "Token ID: 911, Token: ' about'\n",
            "Token ID: 10971, Token: ' flight'\n",
            "Token ID: 29026, Token: ' mechanics'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 74844, Token: ' Penguins'\n",
            "Token ID: 614, Token: ' have'\n",
            "Token ID: 264, Token: ' a'\n",
            "Token ID: 74060, Token: ' streamlined'\n",
            "Token ID: 2487, Token: ' body'\n",
            "Token ID: 323, Token: ' and'\n",
            "Token ID: 2805, Token: ' short'\n",
            "Token ID: 26204, Token: ' wings'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 892, Token: ' which'\n",
            "Token ID: 4658, Token: ' probably'\n",
            "Token ID: 1492, Token: ' help'\n",
            "Token ID: 1105, Token: ' them'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 2379, Token: ' They'\n",
            "Token ID: 1513, Token: ' don'\n",
            "Token ID: 944, Token: ''t'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 448, Token: ' with'\n",
            "Token ID: 26204, Token: ' wings'\n",
            "Token ID: 714, Token: ' but'\n",
            "Token ID: 429, Token: ' that'\n",
            "Token ID: 4977, Token: ' seems'\n",
            "Token ID: 1290, Token: ' right'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 3003, Token: ''ve'\n",
            "Token ID: 6617, Token: ' heard'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 990, Token: ' use'\n",
            "Token ID: 264, Token: ' a'\n",
            "Token ID: 10601, Token: ' combination'\n",
            "Token ID: 315, Token: ' of'\n",
            "Token ID: 1320, Token: ' fl'\n",
            "Token ID: 3629, Token: 'apping'\n",
            "Token ID: 26204, Token: ' wings'\n",
            "Token ID: 323, Token: ' and'\n",
            "Token ID: 1320, Token: ' fl'\n",
            "Token ID: 3629, Token: 'apping'\n",
            "Token ID: 14201, Token: ' legs'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 714, Token: ' but'\n",
            "Token ID: 429, Token: ' that'\n",
            "Token ID: 4977, Token: ' seems'\n",
            "Token ID: 1290, Token: ' right'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 2055, Token: ' So'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 653, Token: ' do'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 382, Token: '.\n",
            "\n",
            "'\n",
            "Token ID: 3983, Token: 'But'\n",
            "Token ID: 429, Token: ' that'\n",
            "Token ID: 4977, Token: ' seems'\n",
            "Token ID: 1290, Token: ' right'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 3003, Token: ''ve'\n",
            "Token ID: 6617, Token: ' heard'\n",
            "Token ID: 281, Token: ' p'\n",
            "Token ID: 55358, Token: 'enguins'\n",
            "Token ID: 525, Token: ' are'\n",
            "Token ID: 10971, Token: ' flight'\n",
            "Token ID: 1717, Token: 'less'\n",
            "Token ID: 304, Token: ' in'\n",
            "Token ID: 39208, Token: ' breeding'\n",
            "Token ID: 3200, Token: ' season'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 773, Token: ' so'\n",
            "Token ID: 7196, Token: ' maybe'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 646, Token: ' can'\n",
            "Token ID: 944, Token: ''t'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 1221, Token: ' then'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 1988, Token: ' But'\n",
            "Token ID: 429, Token: ' that'\n",
            "Token ID: 4977, Token: ' seems'\n",
            "Token ID: 1290, Token: ' right'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 1744, Token: ' think'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 646, Token: ' can'\n",
            "Token ID: 2058, Token: ' still'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 979, Token: ' when'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 2299, Token: ''re'\n",
            "Token ID: 537, Token: ' not'\n",
            "Token ID: 39208, Token: ' breeding'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 892, Token: ' which'\n",
            "Token ID: 374, Token: ' is'\n",
            "Token ID: 979, Token: ' when'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 803, Token: ' more'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 2055, Token: ' So'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 279, Token: ' the'\n",
            "Token ID: 4226, Token: ' answer'\n",
            "Token ID: 374, Token: ' is'\n",
            "Token ID: 9834, Token: ' yes'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 281, Token: ' p'\n",
            "Token ID: 55358, Token: 'enguins'\n",
            "Token ID: 646, Token: ' can'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 382, Token: '.\n",
            "\n",
            "'\n",
            "Token ID: 14190, Token: 'Wait'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 429, Token: ' that'\n",
            "Token ID: 4977, Token: ' seems'\n",
            "Token ID: 1290, Token: ' right'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 1744, Token: ' think'\n",
            "Token ID: 358, Token: ' I'\n",
            "Token ID: 3003, Token: ''ve'\n",
            "Token ID: 6617, Token: ' heard'\n",
            "Token ID: 281, Token: ' p'\n",
            "Token ID: 55358, Token: 'enguins'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 264, Token: ' a'\n",
            "Token ID: 2696, Token: ' lot'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 5310, Token: ' especially'\n",
            "Token ID: 979, Token: ' when'\n",
            "Token ID: 807, Token: ' they'\n",
            "Token ID: 2299, Token: ''re'\n",
            "Token ID: 537, Token: ' not'\n",
            "Token ID: 304, Token: ' in'\n",
            "Token ID: 39208, Token: ' breeding'\n",
            "Token ID: 3200, Token: ' season'\n",
            "Token ID: 13, Token: '.'\n",
            "Token ID: 2055, Token: ' So'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 279, Token: ' the'\n",
            "Token ID: 4226, Token: ' answer'\n",
            "Token ID: 374, Token: ' is'\n",
            "Token ID: 9834, Token: ' yes'\n",
            "Token ID: 11, Token: ','\n",
            "Token ID: 281, Token: ' p'\n",
            "Token ID: 55358, Token: 'enguins'\n",
            "Token ID: 646, Token: ' can'\n",
            "Token ID: 11466, Token: ' fly'\n",
            "Token ID: 624, Token: '.\n",
            "'\n",
            "Token ID: 151649, Token: '</think>'\n",
            "Token ID: 271, Token: '\n",
            "\n",
            "'\n",
            "Token ID: 14004, Token: 'YES'\n",
            "Token ID: 151643, Token: '<｜end▁of▁sentence｜>'\n"
          ]
        }
      ],
      "source": [
        "# Print each token and its corresponding ID\n",
        "for token_id in generated_ids[0]:\n",
        "    token = tokenizer.decode([token_id])\n",
        "    print(f\"Token ID: {token_id.item()}, Token: '{token}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "DVIxgLd2q2na"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer.apply_chat_template(\n",
        "    [\n",
        "        {\"role\": \"user\", \"content\": \"Roleplay as a pirate\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Yarr, I'll be speakin' like a true seafarer from here on out! Got me sea legs ready and me vocabulary set to proper pirate speak. What can I help ye with, me hearty?\"},\n",
        "    ],\n",
        "    return_tensors=\"pt\",\n",
        ").to(\"mps\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded token tensor shape: torch.Size([1, 724])\n",
            "First few tokens: tensor([128000, 128011,   6854,    281,  56458,  11722,     30,  38203,    279,\n",
            "          7422], device='mps:0')\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bt/h53kb9_n1yb13w1c6j1f04v80000gp/T/ipykernel_76905/2392308461.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_tokens = torch.load(pt_file_path)\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the .pt file - you can modify this to any file in the outputs directory\n",
        "pt_file_path = \"outputs/penguin/raw_outputs/output_79_temp0_6.pt\"\n",
        "\n",
        "# Load the tokens from the .pt file\n",
        "loaded_tokens = torch.load(pt_file_path)\n",
        "\n",
        "# Move to the appropriate device\n",
        "inputs = loaded_tokens.to(\"mps\")\n",
        "\n",
        "# Print shape and first few tokens to verify\n",
        "print(f\"Loaded token tensor shape: {inputs.shape}\")\n",
        "print(f\"First few tokens: {inputs[0, :10]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bt/h53kb9_n1yb13w1c6j1f04v80000gp/T/ipykernel_70615/707757656.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  raw_outputs = torch.load(outputs_file, map_location=\"cpu\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input IDs shape: torch.Size([1, 919])\n",
            "Decoded sentence: <｜User｜>\n",
            "Q: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
            "A:<｜Assistant｜><think>\n",
            "Okay, so I have this problem about Janet and her ducks. Let me try to figure it out step by step. \n",
            "\n",
            "First, the problem says that Janet’s ducks lay 16 eggs per day. Hmm, wait, no, actually, it says 16 eggs per day. Let me check: \"Janet’s ducks lay 16 eggs per day.\" Oh, wait, that's 16 eggs per day. So, 16 eggs in total each day. Got it.\n",
            "\n",
            "Then, she eats three eggs for breakfast every morning. So, breakfast is three eggs. And she bakes muffins for her friends every day with four eggs. So, she uses four eggs for muffins. \n",
            "\n",
            "So, let me break this down. She has 16 eggs in total each day. She uses some for breakfast and some for muffins. The rest she sells at the farmers' market for $2 per egg. So, I need to find out how many eggs she sells at the market each day and then multiply that by $2 to get the total earnings.\n",
            "\n",
            "Let me write this out:\n",
            "\n",
            "Total eggs per day: 16\n",
            "\n",
            "Eggs eaten for breakfast: 3\n",
            "\n",
            "Eggs used for muffins: 4\n",
            "\n",
            "So, the eggs sold at the market would be the total minus the ones eaten for breakfast and used for muffins.\n",
            "\n",
            "So, eggs sold = 16 - 3 - 4\n",
            "\n",
            "Let me calculate that: 16 minus 3 is 13, and 13 minus 4 is 9. So, she sells 9 eggs at the market each day.\n",
            "\n",
            "Then, she sells each egg for $2. So, total earnings would be 9 eggs multiplied by $2 per egg.\n",
            "\n",
            "So, 9 * 2 = 18.\n",
            "\n",
            "Therefore, she makes $18 every day at the farmers' market.\n",
            "\n",
            "Wait, let me double-check my calculations to make sure I didn't make a mistake.\n",
            "\n",
            "Total eggs: 16\n",
            "\n",
            "Breakfast: 3\n",
            "\n",
            "Muffins: 4\n",
            "\n",
            "So, 3 + 4 = 7 eggs are used for breakfast and muffins.\n",
            "\n",
            "16 - 7 = 9 eggs left for the market.\n",
            "\n",
            "9 eggs * $2 = $18.\n",
            "\n",
            "Yes, that seems right. So, the answer should be $18.\n",
            "\n",
            "But hold on, let me make sure I interpreted the problem correctly. It says she lays 16 eggs per day. So, 16 total. Then, she eats three for breakfast and bakes four for muffins. So, 3 + 4 = 7 eggs used for her own consumption. So, 16 - 7 = 9 eggs left. Then, she sells the rest. So, 9 * 2 = 18. Yeah, that seems correct.\n",
            "\n",
            "I don't think I made any mistakes here. So, I think the answer is $18.\n",
            "\n",
            "**Final Answer**\n",
            "\\boxed{18}\n",
            "</think>\n",
            "\n",
            "Janet’s ducks lay 16 eggs per day. She eats 3 eggs for breakfast every morning and uses 4 eggs for baking muffins. The remaining eggs are sold at the farmers' market for $2 per egg.\n",
            "\n",
            "First, we calculate the total number of eggs used for breakfast and muffins:\n",
            "\\[\n",
            "3 \\text{ (breakfast)} + 4 \\text{ (muffins)} = 7 \\text{ eggs}\n",
            "\\]\n",
            "\n",
            "Next, we subtract the number of eggs used from the total number of eggs laid:\n",
            "\\[\n",
            "16 \\text{ (total eggs)} - 7 \\text{ (used eggs)} = 9 \\text{ (eggs sold)}\n",
            "\\]\n",
            "\n",
            "Finally, we calculate the total earnings by multiplying the number of eggs sold by the price per egg:\n",
            "\\[\n",
            "9 \\text{ (eggs sold)} \\times 2 \\text{ (dollars per egg)} = 18 \\text{ dollars}\n",
            "\\]\n",
            "\n",
            "Thus, Janet makes \\(\\boxed{18}\\) dollars every day at the farmers' market.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 0 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 1 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 2 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 3 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 4 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 5 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 6 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 7 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 8 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 9 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 10 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 11 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 12 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 13 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 14 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 15 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 16 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 17 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 18 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 19 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 20 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 21 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 22 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 23 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 24 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 25 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 26 activation shape: torch.Size([1, 919, 1536])\n",
            "Layer 27 activation shape: torch.Size([1, 919, 1536])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# Set device (using \"mps\" for Apple Silicon, \"cuda\" for NVIDIA, or CPU as fallback)\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the model name (adjust as needed)\n",
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def extract_all_layer_activations(model, inputs):\n",
        "    \"\"\"\n",
        "    Extracts the activations (residual stream inputs) for each transformer layer.\n",
        "    Assumes that the model has an attribute 'model.layers' which is an iterable of transformer blocks.\n",
        "    \n",
        "    Args:\n",
        "        model: The transformer model.\n",
        "        inputs: A dictionary containing model inputs (e.g., {\"input_ids\": tensor}).\n",
        "        \n",
        "    Returns:\n",
        "        A dictionary mapping layer indices to their activation tensors (shape: [batch_size, seq_length, hidden_dim]).\n",
        "    \"\"\"\n",
        "    layer_activations = {}\n",
        "    hook_handles = []\n",
        "\n",
        "    def get_activation_hook(layer_idx):\n",
        "        def hook(module, layer_input, layer_output):\n",
        "            # Capture the input activations (assumed to be in layer_input[0])\n",
        "            layer_activations[layer_idx] = layer_input[0].detach().cpu()\n",
        "        return hook\n",
        "\n",
        "    # Register a forward hook on each transformer block\n",
        "    for idx, layer in enumerate(model.model.layers):\n",
        "        handle = layer.register_forward_hook(get_activation_hook(idx))\n",
        "        hook_handles.append(handle)\n",
        "\n",
        "    # Run a forward pass with no gradient computation\n",
        "    with torch.no_grad():\n",
        "        _ = model(**inputs)\n",
        "\n",
        "    # Remove hooks to avoid side effects\n",
        "    for handle in hook_handles:\n",
        "        handle.remove()\n",
        "\n",
        "    return layer_activations\n",
        "\n",
        "# Load raw outputs from the .pt file containing model outputs (assumed to be token IDs)\n",
        "outputs_file = \"outputs_small/gsm8k_test/raw_outputs/output_0.pt\"\n",
        "raw_outputs = torch.load(outputs_file, map_location=\"cpu\")\n",
        "\n",
        "# Extract token IDs: if raw_outputs is a dict containing \"input_ids\", use that; otherwise, assume it's a tensor\n",
        "if isinstance(raw_outputs, dict) and \"input_ids\" in raw_outputs:\n",
        "    input_ids = raw_outputs[\"input_ids\"]\n",
        "else:\n",
        "    input_ids = raw_outputs\n",
        "\n",
        "print(\"Input IDs shape:\", input_ids.shape)\n",
        "\n",
        "# Decode the first sequence of token IDs to obtain the human-readable sentence\n",
        "decoded_sentence = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "print(\"Decoded sentence:\", decoded_sentence)\n",
        "\n",
        "# Prepare inputs for the model (moving them to the appropriate device)\n",
        "inputs = {\"input_ids\": input_ids.to(device)}\n",
        "\n",
        "# Extract activations from each transformer layer using the loaded input IDs\n",
        "activations = extract_all_layer_activations(model, inputs)\n",
        "\n",
        "# Print out the activation shape for each layer (each token in the sequence represents a time point)\n",
        "for layer_idx, act_tensor in activations.items():\n",
        "    print(f\"Layer {layer_idx} activation shape: {act_tensor.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bt/h53kb9_n1yb13w1c6j1f04v80000gp/T/ipykernel_76775/3844395558.py:65: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  raw_outputs = torch.load(outputs_file, map_location=\"cpu\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input IDs shape: torch.Size([1, 919])\n",
            "Decoded sentence: <｜User｜>\n",
            "Q: Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?\n",
            "A:<｜Assistant｜><think>\n",
            "Okay, so I have this problem about Janet and her ducks. Let me try to figure it out step by step. \n",
            "\n",
            "First, the problem says that Janet’s ducks lay 16 eggs per day. Hmm, wait, no, actually, it says 16 eggs per day. Let me check: \"Janet’s ducks lay 16 eggs per day.\" Oh, wait, that's 16 eggs per day. So, 16 eggs in total each day. Got it.\n",
            "\n",
            "Then, she eats three eggs for breakfast every morning. So, breakfast is three eggs. And she bakes muffins for her friends every day with four eggs. So, she uses four eggs for muffins. \n",
            "\n",
            "So, let me break this down. She has 16 eggs in total each day. She uses some for breakfast and some for muffins. The rest she sells at the farmers' market for $2 per egg. So, I need to find out how many eggs she sells at the market each day and then multiply that by $2 to get the total earnings.\n",
            "\n",
            "Let me write this out:\n",
            "\n",
            "Total eggs per day: 16\n",
            "\n",
            "Eggs eaten for breakfast: 3\n",
            "\n",
            "Eggs used for muffins: 4\n",
            "\n",
            "So, the eggs sold at the market would be the total minus the ones eaten for breakfast and used for muffins.\n",
            "\n",
            "So, eggs sold = 16 - 3 - 4\n",
            "\n",
            "Let me calculate that: 16 minus 3 is 13, and 13 minus 4 is 9. So, she sells 9 eggs at the market each day.\n",
            "\n",
            "Then, she sells each egg for $2. So, total earnings would be 9 eggs multiplied by $2 per egg.\n",
            "\n",
            "So, 9 * 2 = 18.\n",
            "\n",
            "Therefore, she makes $18 every day at the farmers' market.\n",
            "\n",
            "Wait, let me double-check my calculations to make sure I didn't make a mistake.\n",
            "\n",
            "Total eggs: 16\n",
            "\n",
            "Breakfast: 3\n",
            "\n",
            "Muffins: 4\n",
            "\n",
            "So, 3 + 4 = 7 eggs are used for breakfast and muffins.\n",
            "\n",
            "16 - 7 = 9 eggs left for the market.\n",
            "\n",
            "9 eggs * $2 = $18.\n",
            "\n",
            "Yes, that seems right. So, the answer should be $18.\n",
            "\n",
            "But hold on, let me make sure I interpreted the problem correctly. It says she lays 16 eggs per day. So, 16 total. Then, she eats three for breakfast and bakes four for muffins. So, 3 + 4 = 7 eggs used for her own consumption. So, 16 - 7 = 9 eggs left. Then, she sells the rest. So, 9 * 2 = 18. Yeah, that seems correct.\n",
            "\n",
            "I don't think I made any mistakes here. So, I think the answer is $18.\n",
            "\n",
            "**Final Answer**\n",
            "\\boxed{18}\n",
            "</think>\n",
            "\n",
            "Janet’s ducks lay 16 eggs per day. She eats 3 eggs for breakfast every morning and uses 4 eggs for baking muffins. The remaining eggs are sold at the farmers' market for $2 per egg.\n",
            "\n",
            "First, we calculate the total number of eggs used for breakfast and muffins:\n",
            "\\[\n",
            "3 \\text{ (breakfast)} + 4 \\text{ (muffins)} = 7 \\text{ eggs}\n",
            "\\]\n",
            "\n",
            "Next, we subtract the number of eggs used from the total number of eggs laid:\n",
            "\\[\n",
            "16 \\text{ (total eggs)} - 7 \\text{ (used eggs)} = 9 \\text{ (eggs sold)}\n",
            "\\]\n",
            "\n",
            "Finally, we calculate the total earnings by multiplying the number of eggs sold by the price per egg:\n",
            "\\[\n",
            "9 \\text{ (eggs sold)} \\times 2 \\text{ (dollars per egg)} = 18 \\text{ dollars}\n",
            "\\]\n",
            "\n",
            "Thus, Janet makes \\(\\boxed{18}\\) dollars every day at the farmers' market.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Layer 0 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 1 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 2 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 3 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 4 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 5 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 6 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 7 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 8 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 9 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 10 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 11 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 12 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 13 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 14 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 15 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 16 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 17 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 18 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 19 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 20 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 21 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 22 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 23 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 24 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 25 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 26 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Layer 27 attention head activation shape: torch.Size([1, 919, 12, 128])\n",
            "Final hidden state shape: torch.Size([1, 919, 1536])\n",
            "Final pre-softmax logits shape: torch.Size([1, 919, 151936])\n",
            "All activations saved to saved_activations/model_activations.pt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import os\n",
        "\n",
        "# Set device (using \"mps\" for Apple Silicon, \"cuda\" for NVIDIA, or CPU as fallback)\n",
        "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the model name (adjust as needed)\n",
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"auto\")\n",
        "model.to(device)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "def extract_attention_heads(model, inputs):\n",
        "    \"\"\"\n",
        "    Extracts the attention head outputs for each transformer layer.\n",
        "    Assumes each layer has an attribute `self_attn` (the self-attention module).\n",
        "    The self-attention module produces an output of shape [B, T, hidden_size],\n",
        "    which is then reshaped into [B, T, num_heads, head_dim].\n",
        "    \n",
        "    Args:\n",
        "        model: The transformer model.\n",
        "        inputs: A dictionary containing model inputs (e.g., {\"input_ids\": tensor}).\n",
        "        \n",
        "    Returns:\n",
        "        A dictionary mapping layer indices to their attention head activations.\n",
        "    \"\"\"\n",
        "    attention_activations = {}\n",
        "    hook_handles = []\n",
        "\n",
        "    def get_attn_hook(layer_idx):\n",
        "        def hook(module, layer_input, layer_output):\n",
        "            # If layer_output is a tuple, extract the first element\n",
        "            layer_output_tensor = layer_output[0] if isinstance(layer_output, tuple) else layer_output\n",
        "\n",
        "            # Expected shape: [B, T, hidden_size]\n",
        "            batch_size, seq_length, hidden_size = layer_output_tensor.shape\n",
        "            # Use the module attribute 'num_heads' if available\n",
        "            num_heads = module.num_heads if hasattr(module, \"num_heads\") else 1\n",
        "            head_dim = hidden_size // num_heads\n",
        "            # Reshape to [B, T, num_heads, head_dim]\n",
        "            attn_heads = layer_output_tensor.view(batch_size, seq_length, num_heads, head_dim)\n",
        "            attention_activations[layer_idx] = attn_heads.detach().cpu()\n",
        "        return hook\n",
        "\n",
        "    # Register a hook on each transformer layer's self-attention module (assumed at layer.self_attn)\n",
        "    for idx, layer in enumerate(model.model.layers):\n",
        "        handle = layer.self_attn.register_forward_hook(get_attn_hook(idx))\n",
        "        hook_handles.append(handle)\n",
        "\n",
        "    # Run the forward pass (no gradients needed)\n",
        "    with torch.no_grad():\n",
        "        _ = model(**inputs)\n",
        "\n",
        "    # Remove hooks to avoid interference with future runs\n",
        "    for handle in hook_handles:\n",
        "        handle.remove()\n",
        "\n",
        "    return attention_activations\n",
        "\n",
        "# Load raw outputs from the .pt file containing model outputs (assumed to be token IDs)\n",
        "outputs_file = \"outputs_small/gsm8k_test/raw_outputs/output_0.pt\"\n",
        "raw_outputs = torch.load(outputs_file, map_location=\"cpu\")\n",
        "\n",
        "# Extract token IDs: if raw_outputs is a dict containing \"input_ids\", use that; otherwise assume it's a tensor\n",
        "if isinstance(raw_outputs, dict) and \"input_ids\" in raw_outputs:\n",
        "    input_ids = raw_outputs[\"input_ids\"]\n",
        "else:\n",
        "    input_ids = raw_outputs\n",
        "\n",
        "print(\"Input IDs shape:\", input_ids.shape)\n",
        "\n",
        "# Decode the first sequence of token IDs into a human-readable sentence\n",
        "decoded_sentence = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "print(\"Decoded sentence:\", decoded_sentence)\n",
        "\n",
        "# Prepare inputs for the model (move them to the appropriate device)\n",
        "inputs = {\"input_ids\": input_ids.to(device)}\n",
        "\n",
        "# Extract attention head activations from each transformer layer\n",
        "attention_activations = extract_attention_heads(model, inputs)\n",
        "for layer_idx, attn_tensor in attention_activations.items():\n",
        "    print(f\"Layer {layer_idx} attention head activation shape: {attn_tensor.shape}\")\n",
        "\n",
        "# Now, extract the final hidden state and the final pre-softmax logits.\n",
        "# We'll perform a forward pass with output_hidden_states=True.\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs, output_hidden_states=True)\n",
        "    # outputs.hidden_states is a tuple containing the embeddings plus the output of each layer.\n",
        "    # The final hidden state is the output of the last transformer block.\n",
        "    final_hidden_state = outputs.hidden_states[-1]\n",
        "    \n",
        "    # Extract logits: either via dictionary key \"logits\" or the first element if tuple.\n",
        "    logits = outputs[\"logits\"] if isinstance(outputs, dict) and \"logits\" in outputs else outputs[0]\n",
        "\n",
        "# Move final hidden state and logits to CPU and print their shapes.\n",
        "final_hidden_state = final_hidden_state.detach().cpu()\n",
        "logits = logits.detach().cpu()\n",
        "print(\"Final hidden state shape:\", final_hidden_state.shape)\n",
        "print(\"Final pre-softmax logits shape:\", logits.shape)\n",
        "\n",
        "# Create a dictionary to store all activations and logits\n",
        "all_activations = {\n",
        "    \"attention_activations\": attention_activations,\n",
        "    \"final_hidden_state\": final_hidden_state,\n",
        "    \"logits\": logits,\n",
        "    \"input_ids\": input_ids\n",
        "}\n",
        "\n",
        "# Create directory if it doesn't exist\n",
        "os.makedirs(\"saved_activations\", exist_ok=True)\n",
        "\n",
        "# Save the dictionary as a .pt file\n",
        "torch.save(all_activations, \"saved_activations/model_activations.pt\")\n",
        "print(\"All activations saved to saved_activations/model_activations.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loaded activations structure:\n",
            "attention_activations:\n",
            "  Layer 0 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 1 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 2 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 3 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 4 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 5 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 6 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 7 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 8 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 9 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 10 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 11 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 12 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 13 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 14 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 15 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 16 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 17 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 18 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 19 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 20 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 21 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 22 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 23 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 24 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 25 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 26 shape: torch.Size([1, 919, 12, 128])\n",
            "  Layer 27 shape: torch.Size([1, 919, 12, 128])\n",
            "final_hidden_state shape: torch.Size([1, 919, 1536])\n",
            "logits shape: torch.Size([1, 919, 151936])\n",
            "input_ids shape: torch.Size([1, 919])\n",
            "\n",
            "Successfully loaded and analyzed saved activations.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/bt/h53kb9_n1yb13w1c6j1f04v80000gp/T/ipykernel_76775/1207445662.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  loaded_activations = torch.load(\"saved_activations/model_activations.pt\")\n"
          ]
        }
      ],
      "source": [
        "# Load the saved activations\n",
        "loaded_activations = torch.load(\"saved_activations/model_activations.pt\")\n",
        "\n",
        "# Print the structure of the loaded activations\n",
        "print(\"\\nLoaded activations structure:\")\n",
        "for key in loaded_activations:\n",
        "    if key == \"attention_activations\":\n",
        "        print(f\"{key}:\")\n",
        "        for layer_idx, attn_tensor in loaded_activations[key].items():\n",
        "            print(f\"  Layer {layer_idx} shape: {attn_tensor.shape}\")\n",
        "    else:\n",
        "        print(f\"{key} shape: {loaded_activations[key].shape}\")\n",
        "\n",
        "# Access specific components if needed\n",
        "attention_activations = loaded_activations[\"attention_activations\"]\n",
        "final_hidden_state = loaded_activations[\"final_hidden_state\"]\n",
        "logits = loaded_activations[\"logits\"]\n",
        "input_ids = loaded_activations[\"input_ids\"]\n",
        "\n",
        "print(\"\\nSuccessfully loaded and analyzed saved activations.\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "arena-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
